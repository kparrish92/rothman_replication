dv = "n_correct",
between = "L1",
within = "pre_post",
data = aov_df_col,
print.formula = T
)
source(here::here("scripts", "00_libs.R"))
source(here("scripts", "04_load_data.R"))
### aov collocation task
col_mod_aov <-
afex::aov_ez(
id = "gorilla_id",
dv = "n_correct",
between = "L1",
within = "pre_post",
data = aov_df_col,
print.formula = T
)
df_aov_col = col_mod_aov[["anova_table"]] %>%
rename("num_df" = `num Df`) %>%
rename("den_df" = `den Df`) %>%
rename("p.value" = `Pr(>F)`)
### aov interpretation task
int_mod_aov <-
afex::aov_ez(
id = "gorilla_id",
dv = "n_correct",
between = "L1",
within = "pre_post",
data = aov_df_int,
print.formula = T
)
df_aov_int = int_mod_aov[["anova_table"]] %>%
rename("num_df" = `num Df`) %>%
rename("den_df" = `den Df`) %>%
rename("p.value" = `Pr(>F)`)
### initial run - no main effect of group in both tasks. coll task had
### a main effect for pre-post, and int had the interaction.
d_df = aov_df_col %>%
group_by(pre_post, L1) %>%
summarize(mean_corr = mean(n_correct),
n = n(),
sd_corr = sd(n_correct))
# TOST of col task in post
col_tost_post = TOSTER::tsum_TOST(m1 = d_df$mean_corr[1],
sd1 = d_df$sd_corr[1],
n1 = d_df$n[1],
m2 = d_df$mean_corr[2],
sd2 = d_df$sd_corr[2],
n2 = d_df$n[2],
low_eqbound = -.4,
high_eqbound = .4,
alpha = .05,
eqbound_type = c("SMD"))
col_post_df = col_tost_post[["TOST"]]
col_post_df_eq = col_tost_post[["eqb"]]
col_post_df_es = col_tost_post[["effsize"]]
# TOST of col task in pre
col_tost_pre = TOSTER::tsum_TOST(m1 = d_df$mean_corr[3],
sd1 = d_df$sd_corr[3],
n1 = d_df$n[3],
m2 = d_df$mean_corr[4],
sd2 = d_df$sd_corr[4],
n2 = d_df$n[4],
low_eqbound = -.4,
high_eqbound = .4,
alpha = .05,
eqbound_type = c("SMD"))
col_pre_df = col_tost_pre[["TOST"]]
col_pre_df_eq = col_tost_pre[["eqb"]]
col_pre_df_es = col_tost_pre[["effsize"]]
d_df_i = aov_df_int %>%
group_by(pre_post, L1) %>%
summarize(mean_corr = mean(n_correct),
n = n(),
sd_corr = sd(n_correct))
# TOST of sem task in post
sem_tost_post = TOSTER::tsum_TOST(m1 = d_df_i$mean_corr[1],
sd1 = d_df_i$sd_corr[1],
n1 = d_df_i$n[1],
m2 = d_df_i$mean_corr[2],
sd2 = d_df_i$sd_corr[2],
n2 = d_df_i$n[2],
low_eqbound = -.4,
high_eqbound = .4,
alpha = .05,
eqbound_type = c("SMD"))
sem_post_df = sem_tost_post[["TOST"]]
sem_post_df_eq = sem_tost_post[["eqb"]]
sem_post_df_es = sem_tost_post[["effsize"]]
# TOST of sem task in pre
sem_tost_pre = TOSTER::tsum_TOST(m1 = d_df_i$mean_corr[3],
sd1 = d_df_i$sd_corr[3],
n1 = d_df_i$n[3],
m2 = d_df_i$mean_corr[4],
sd2 = d_df_i$sd_corr[4],
n2 = d_df_i$n[4],
low_eqbound = -.4,
high_eqbound = .4,
alpha = .05,
eqbound_type = c("SMD"))
sem_pre_df = sem_tost_pre[["TOST"]]
sem_pre_df_eq = sem_tost_pre[["eqb"]]
sem_pre_df_eq = sem_tost_pre[["effsize"]]
library("papaja")
library(gtsummary)
r_refs("r-references.bib")
source(here::here("scripts", "00_libs.R"))
source(here("scripts", "04_load_data.R"))
source(here("scripts", "05_analysis.R"))
source(here("scripts", "09_small_data.R"))
## Load Libraries and data
source(here::here("scripts", "00_libs.R"))
source(here("scripts", "04_load_data.R"))
## Tidy collocation task for proficiency in each language per group
prof_df = collocation_task %>%
group_by(prolific_id, L1) %>%
summarise(English = mean(lextale_score_eng),
Spanish = mean(lextale_score_span),
Portuguese = mean(lextale_score_port)) %>%
pivot_longer(cols = c("English", "Spanish", "Portuguese"),
names_to = "Language",
values_to = "Score")
prof_df %>%
ggplot(aes(y = Score, x = Language, fill = L1)) +
geom_boxplot() + theme_minimal() +
scale_fill_manual(values=c("#E69F00", "#56B4E9"))
desc_all = collocation_task %>%
group_by(prolific_id, pre_post, L1) %>%
summarize(n_correct = sum(is_correct))
mean_correct = desc_all %>%
group_by(L1, pre_post) %>%
summarize(mean_c = mean(n_correct),
sd_c = sd(n_correct))
ggplot(data=mean_correct, aes(x=pre_post, y=mean_c, fill=L1)) +
geom_bar(color = "black", position = 'dodge', stat='identity') +
geom_text(aes(label=paste0(round(mean_c, digits = 2), " (",
round(sd_c, digits = 1), ")")),
position=position_dodge(width=0.9), vjust=-0.5, size = 3) +
ylim(0,5) +
theme_minimal() +
ylab("Group mean (correct)") +
theme(legend.position="bottom"
)
ggplot(data=mean_correct_i, aes(x=pre_post, y=mean_c, fill=L1)) +
geom_bar(color = "black", position = 'dodge', stat='identity') +
geom_text(aes(label=paste0(round(mean_c, digits = 2), " (",
round(sd_c, digits = 1), ")")),
position=position_dodge(width=0.9), vjust=-0.5, size = 3) +
ylim(0,5) +
theme_minimal() +
ylab("Group mean (correct)") +
theme(legend.position="bottom")
## Tidy Interpretation Task for plotting
desc_all_i = interpretation_task %>%
group_by(prolific_id, pre_post, L1) %>%
summarize(n_correct = sum(is_correct))
mean_correct_i = desc_all_i %>%
group_by(L1, pre_post) %>%
summarize(mean_c = mean(n_correct),
sd_c = sd(n_correct))
## Figure 3: Average Number of correct answers in the Semantic Interpretation Task
ggplot(data=mean_correct_i, aes(x=pre_post, y=mean_c, fill=L1)) +
geom_bar(color = "black", position = 'dodge', stat='identity') +
geom_text(aes(label=paste0(round(mean_c, digits = 2), " (",
round(sd_c, digits = 1), ")")),
position=position_dodge(width=0.9), vjust=-0.5, size = 3) +
ylim(0,5) +
theme_minimal() +
ylab("Group mean (correct)") +
theme(legend.position="bottom")
# plot models
df_col_prof_eng =
conditional_effects(col_bda)[["lextale_score_eng:L1"]] %>%
mutate(language = "English") %>%
select(lextale_score_eng, L1, pre_post, estimate__, se__, language) %>%
rename("LexTALE score" = lextale_score_eng)
power_curve_t_df = data.frame(num_needed = round(c(pwr.2p.test(h = .1, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .2, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .3, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .4, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .5, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .6, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .7, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .8, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .9, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = 1, n = NULL, sig.level = 0.05, power = .8)[["n"]])),
sesoi = c(.1, .2, .3, .4, .5, .6, .7, .8, .9, 1))
power_curve_t_df %>%
ggplot(aes(x = as.factor(sesoi), y = num_needed, label = num_needed)) +
geom_col(fill = "skyblue", color = "black") +
geom_label(nudge_y = 100) +
xlab("Smallest Effect Size of Interest") +
ylab("Participants per group") +
theme_minimal() +
theme(axis.text.y = element_blank(),
axis.ticks = element_blank())
# ------------------------------------------------------
# Date 11/9/23
# This script creates the plots used in the manuscript
# -------------------------------------------------------
## Load Libraries and data
source(here::here("scripts", "00_libs.R"))
source(here("scripts", "04_load_data.R"))
## Tidy collocation task for proficiency in each language per group
prof_df = collocation_task %>%
group_by(prolific_id, L1) %>%
summarise(English = mean(lextale_score_eng),
Spanish = mean(lextale_score_span),
Portuguese = mean(lextale_score_port)) %>%
pivot_longer(cols = c("English", "Spanish", "Portuguese"),
names_to = "Language",
values_to = "Score")
## Figure 1: LexTALE score as a function of Language and Group
prof_df %>%
ggplot(aes(y = Score, x = Language, fill = L1)) +
geom_boxplot() + theme_minimal() +
scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
ggsave(here("docs", "figs", "prof_plot.png"))
ggplot(data=mean_correct, aes(x=pre_post, y=mean_c, fill=L1)) +
geom_bar(color = "black", position = 'dodge', stat='identity') +
geom_text(aes(label=paste0(round(mean_c, digits = 2), " (",
round(sd_c, digits = 1), ")")),
position=position_dodge(width=0.9), vjust=-0.5, size = 3) +
ylim(0,5) +
theme_minimal() +
ylab("Group mean (correct)") +
theme(legend.position="bottom") +
ggsave(here("docs", "figs", "cbc_desc.png"))
ggplot(data=mean_correct_i, aes(x=pre_post, y=mean_c, fill=L1)) +
geom_bar(color = "black", position = 'dodge', stat='identity') +
geom_text(aes(label=paste0(round(mean_c, digits = 2), " (",
round(sd_c, digits = 1), ")")),
position=position_dodge(width=0.9), vjust=-0.5, size = 3) +
ylim(0,5) +
theme_minimal() +
ylab("Group mean (correct)") +
theme(legend.position="bottom") +
ggsave(here("docs", "figs", "semantic_desc.png"))
power_curve_tost_df = data.frame(num_needed = round(c(powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.1, high_eqbound_d=0.1),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.2, high_eqbound_d=0.2),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.3, high_eqbound_d=0.3),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.4, high_eqbound_d=0.4),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.5, high_eqbound_d=0.5),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.6, high_eqbound_d=0.6),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.7, high_eqbound_d=0.7),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.8, high_eqbound_d=0.8),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.9, high_eqbound_d=0.9),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-1, high_eqbound_d=1))),
sesoi = c(.1, .2, .3, .4, .5, .6, .7, .8, .9, 1))
library(pwr)
## Generate data for Figure 4
power_curve_tost_df = data.frame(num_needed = round(c(powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.1, high_eqbound_d=0.1),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.2, high_eqbound_d=0.2),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.3, high_eqbound_d=0.3),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.4, high_eqbound_d=0.4),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.5, high_eqbound_d=0.5),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.6, high_eqbound_d=0.6),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.7, high_eqbound_d=0.7),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.8, high_eqbound_d=0.8),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.9, high_eqbound_d=0.9),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-1, high_eqbound_d=1))),
sesoi = c(.1, .2, .3, .4, .5, .6, .7, .8, .9, 1))
?powerTOSTtwo
library(TOSTER)
## Generate data for Figure 4
power_curve_tost_df = data.frame(num_needed = round(c(powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.1, high_eqbound_d=0.1),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.2, high_eqbound_d=0.2),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.3, high_eqbound_d=0.3),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.4, high_eqbound_d=0.4),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.5, high_eqbound_d=0.5),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.6, high_eqbound_d=0.6),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.7, high_eqbound_d=0.7),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.8, high_eqbound_d=0.8),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.9, high_eqbound_d=0.9),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-1, high_eqbound_d=1))),
sesoi = c(.1, .2, .3, .4, .5, .6, .7, .8, .9, 1))
power_curve_tost_df %>%
ggplot(aes(x = as.factor(sesoi), y = num_needed, label = num_needed)) +
geom_col(fill = "seagreen", color = "black") +
geom_label(nudge_y = 100) +
xlab("Smallest Effect Size of Interest") +
ylab("Participants per group") +
theme_minimal() +
theme(axis.text.y = element_blank(),
axis.ticks = element_blank())
# ------------------------------------------------------
# Date 11/9/23
# This script creates the plots used in the manuscript
# -------------------------------------------------------
## Load Libraries and data
source(here::here("scripts", "00_libs.R"))
source(here("scripts", "04_load_data.R"))
## Tidy collocation task for proficiency in each language per group
prof_df = collocation_task %>%
group_by(prolific_id, L1) %>%
summarise(English = mean(lextale_score_eng),
Spanish = mean(lextale_score_span),
Portuguese = mean(lextale_score_port)) %>%
pivot_longer(cols = c("English", "Spanish", "Portuguese"),
names_to = "Language",
values_to = "Score")
## Figure 1: LexTALE score as a function of Language and Group
prof_df %>%
ggplot(aes(y = Score, x = Language, fill = L1)) +
geom_boxplot() + theme_minimal() +
scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
ggsave(here("docs", "figs", "prof_plot.png"))
## Generate data for Figure 4
power_curve_tost_df = data.frame(num_needed = round(c(powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.1, high_eqbound_d=0.1),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.2, high_eqbound_d=0.2),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.3, high_eqbound_d=0.3),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.4, high_eqbound_d=0.4),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.5, high_eqbound_d=0.5),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.6, high_eqbound_d=0.6),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.7, high_eqbound_d=0.7),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.8, high_eqbound_d=0.8),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-0.9, high_eqbound_d=0.9),
powerTOSTtwo(alpha=0.05, statistical_power=0.8, low_eqbound_d=-1, high_eqbound_d=1))),
sesoi = c(.1, .2, .3, .4, .5, .6, .7, .8, .9, 1))
## Plot Figure 4
power_curve_tost_df %>%
ggplot(aes(x = as.factor(sesoi), y = num_needed, label = num_needed)) +
geom_col(fill = "seagreen", color = "black") +
geom_label(nudge_y = 100) +
xlab("Smallest Effect Size of Interest") +
ylab("Participants per group") +
theme_minimal() +
theme(axis.text.y = element_blank(),
axis.ticks = element_blank()) +
ggsave(here("docs", "figs", "pc.png"))
## Generate data for Figure 5
power_curve_t_df = data.frame(num_needed = round(c(pwr.2p.test(h = .1, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .2, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .3, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .4, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .5, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .6, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .7, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .8, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = .9, n = NULL, sig.level = 0.05, power = .8)[["n"]],
pwr.2p.test(h = 1, n = NULL, sig.level = 0.05, power = .8)[["n"]])),
sesoi = c(.1, .2, .3, .4, .5, .6, .7, .8, .9, 1))
## Plot Figure 5
power_curve_t_df %>%
ggplot(aes(x = as.factor(sesoi), y = num_needed, label = num_needed)) +
geom_col(fill = "skyblue", color = "black") +
geom_label(nudge_y = 100) +
xlab("Smallest Effect Size of Interest") +
ylab("Participants per group") +
theme_minimal() +
theme(axis.text.y = element_blank(),
axis.ticks = element_blank()) +
ggsave(here("docs", "figs", "pc_t.png"))
# ------------------------------------------------------
# Date 11/9/23
# This script creates the plots used in the manuscript
# -------------------------------------------------------
## Load Libraries and data
source(here::here("scripts", "00_libs.R"))
source(here("scripts", "04_load_data.R"))
## Tidy collocation task for proficiency in each language per group
prof_df = collocation_task %>%
group_by(prolific_id, L1) %>%
summarise(English = mean(lextale_score_eng),
Spanish = mean(lextale_score_span),
Portuguese = mean(lextale_score_port)) %>%
pivot_longer(cols = c("English", "Spanish", "Portuguese"),
names_to = "Language",
values_to = "Score")
## Figure 1: LexTALE score as a function of Language and Group
prof_df %>%
ggplot(aes(y = Score, x = Language, fill = L1)) +
geom_boxplot() + theme_minimal() +
scale_fill_manual(values=c("#E69F00", "#56B4E9")) +
ggsave(here("docs", "figs", "prof_plot.png"))
library("papaja")
library(gtsummary)
r_refs("r-references.bib")
source(here::here("scripts", "00_libs.R"))
source(here("scripts", "04_load_data.R"))
source(here("scripts", "05_analysis.R"))
#source(here("scripts", "09_small_data.R"))
library("papaja")
library(gtsummary)
r_refs("r-references.bib")
source(here::here("scripts", "00_libs.R"))
source(here("scripts", "04_load_data.R"))
source(here("scripts", "05_analysis.R"))
#source(here("scripts", "09_small_data.R"))
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
knitr::include_graphics(here("docs", "figs", "prof_plot.png"))
ound(mean(c(d_df_i$sd_corr, d_df$sd_corr)), digits = 1)
ound(mean(c(d_df_i$sd_corr, d_df$sd_corr)), digits = 1)
round(mean(c(d_df_i$sd_corr, d_df$sd_corr)), digits = 1)
library("papaja")
library(gtsummary)
r_refs("r-references.bib")
source(here::here("scripts", "00_libs.R"))
source(here("scripts", "04_load_data.R"))
source(here("scripts", "05_analysis.R"))
round(mean(c(d_df_i$sd_corr, d_df$sd_corr)), digits = 1)
round(res[1], digits = 2)
round(res[1], digits = 2)
TOSTER::power_t_TOST(
n = NULL,
delta = 0,
sd = 27,
low_eqbound = -.4,
high_eqbound = .4,
alpha = .05,
power = .8,
type = "two.sample"
)
# ------------------------------------------------------
# Date 11/9/23
# This script simulates data for the purpose of determining
# the needed sample size
# -------------------------------------------------------
# Code for a two sample power analysis that runs both a t.test and tost
#number of iterations
k = 1000
temp_df = matrix(nrow = k, ncol = 2)
outer_df = matrix(nrow = 7, ncol = 3)
sizes = c(60,70,80,90,100,110,120)
for(thisSize in 1:nrow(outer_df)){
for(thisRun in 1:k){
mv1 = rnorm(95, m = 3.2, sd = 1.3)
mv2 = rnorm(115, m = 3.2, sd = 1.3)
tost = TOSTER::TOSTtwo(m1 = mean(mv1), m2 = mean(mv2), sd1 = sd(mv1), sd2 = sd(mv2),
n1 = sizes[thisSize], n2 = sizes[thisSize], low_eqbound_d = -.4, high_eqbound_d = .4, alpha = .05,
plot = TRUE, verbose = TRUE)
t_test_df = t.test(mv1, mv2, paired = FALSE)
temp_df[thisRun, 1] = pmax(tost$TOST_p1, tost$TOST_p2)
temp_df[thisRun, 2] = t_test_df$p.value
temp_df = as.data.frame(temp_df)
}
outer_df[thisSize, 1] = sizes[thisSize]
outer_df[thisSize, 2] = sum(temp_df$V1 < .05) # tost positives
outer_df[thisSize, 3] = sum(temp_df$V2 < .05) # (false) t-test positives
}
View(outer_df)
as.data.frame(outer_df)
source("~/Documents/GitHub/rothman_replication/scripts/99b_sample_size_justification.R", echo=TRUE)
as.data.frame(outer_df) %>%
rename(V1 == "Sample Size")
# ------------------------------------------------------
# Date 11/9/23
# This script simulates data for the purpose of determining
# the needed sample size
# -------------------------------------------------------
# Code for a two sample power analysis that runs both a t.test and tost
#number of iterations
k = 1000
temp_df = matrix(nrow = k, ncol = 2)
outer_df = matrix(nrow = 7, ncol = 3)
sizes = c(60,70,80,90,100,110,120)
for(thisSize in 1:nrow(outer_df)){
for(thisRun in 1:k){
mv1 = rnorm(95, m = 3.2, sd = 1.3)
mv2 = rnorm(115, m = 3.2, sd = 1.3)
tost = TOSTER::TOSTtwo(m1 = mean(mv1), m2 = mean(mv2), sd1 = sd(mv1), sd2 = sd(mv2),
n1 = sizes[thisSize], n2 = sizes[thisSize], low_eqbound_d = -.4, high_eqbound_d = .4, alpha = .05,
plot = TRUE, verbose = TRUE)
t_test_df = t.test(mv1, mv2, paired = FALSE)
temp_df[thisRun, 1] = pmax(tost$TOST_p1, tost$TOST_p2)
temp_df[thisRun, 2] = t_test_df$p.value
temp_df = as.data.frame(temp_df)
}
outer_df[thisSize, 1] = sizes[thisSize]
outer_df[thisSize, 2] = sum(temp_df$V1 < .05) # tost positives
outer_df[thisSize, 3] = sum(temp_df$V2 < .05) # (false) t-test positives
}
# tidy results of loop to make the output readable
as.data.frame(outer_df) %>%
rename(V1 == "Sample Size")
sample_needed = as.data.frame(outer_df) %>%
rename(V1 == "Sample Size")
sample_needed = as.data.frame(outer_df) %>%
rename("Sample Size" == V1)
sample_needed = as.data.frame(outer_df) %>%
rename("Sample Size" = V1)
View(sample_needed)
sample_needed = as.data.frame(outer_df) %>%
rename("Sample Size" = V1) %>%
mutate(V2 = V2/1000)
sample_needed = as.data.frame(outer_df) %>%
rename("Sample Size" = V1) %>%
mutate(V2 = V2/1000) %>%
mutate(V3 = V3/1000) %>%
rename("Pct Positive TOST" = V2) %>%
rename("Pct Positive T-test" = V3) %>%
sample_needed = as.data.frame(outer_df) %>%
rename("Sample Size" = V1) %>%
mutate(V2 = V2/1000) %>%
mutate(V3 = V3/1000) %>%
rename("Pct Positive TOST" = V2) %>%
rename("Pct Positive T-test" = V3)
sample_needed = as.data.frame(outer_df) %>%
rename("Sample Size" = V1) %>%
mutate(V2 = V2/1000) %>%
mutate(V3 = V3/1000) %>%
rename("Pct Positive TOST" = V2) %>%
rename("Pct Positive T-test" = V3)
sample_needed = as.data.frame(outer_df) %>%
rename("Sample Size" = V1) %>%
mutate(V2 = V2/1000) %>%
mutate(V3 = V3/1000) %>%
rename("Pct Positive TOST" = V2) %>%
rename("Pct Positive T-test" = V3)
